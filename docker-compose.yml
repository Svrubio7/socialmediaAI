# =============================================================================
# Social Media AI - Docker Compose (Development)
# Full local development stack with hot reload support.
#
# Database: Supabase only. Set DATABASE_URL in backend/.env to your Supabase
# Postgres connection string (Project Settings → Database → Connection string).
# No local Postgres container; frontend and backend run as separate containers.
#
# Usage:
#   docker-compose up -d          # Start all services
#   docker-compose logs -f        # View logs
#   docker-compose down           # Stop all services
#   docker-compose down -v        # Stop and remove volumes
# =============================================================================

services:
  # ===========================================================================
  # nginx - Reverse Proxy
  # ===========================================================================
  nginx:
    image: nginx:alpine
    container_name: socialmediaai-nginx
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.dev.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      backend:
        condition: service_healthy
      frontend:
        condition: service_started
    networks:
      - socialmediaai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/nginx-health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ===========================================================================
  # Frontend - Nuxt.js (Development with Hot Reload)
  # ===========================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: deps
    container_name: socialmediaai-frontend
    ports:
      - "3000:3000"
    env_file:
      - frontend/.env
    volumes:
      # Mount source code for hot reload
      - ./frontend:/app
      # Prevent overwriting node_modules
      - /app/node_modules
    environment:
      - NODE_ENV=development
      # Override API URL for nginx proxy when using Docker
      - NUXT_PUBLIC_API_URL=http://localhost/api/v1
      # NUXT_PUBLIC_SUPABASE_URL and NUXT_PUBLIC_SUPABASE_ANON_KEY come from env_file (frontend/.env)
    command: npm run dev -- --host 0.0.0.0
    networks:
      - socialmediaai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ===========================================================================
  # Backend - FastAPI (Development with Hot Reload)
  # ===========================================================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: socialmediaai-backend
    ports:
      - "8000:8000"
    env_file:
      - backend/.env
    volumes:
      # Mount source code for hot reload
      - ./backend:/app
      # Temp directory for video processing
      - backend-temp:/app/temp
    environment:
      - DEBUG=true
      # Redis for Celery; DATABASE_URL from backend/.env (Supabase Postgres connection string)
      - REDIS_URL=redis://redis:6379
    command: uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - socialmediaai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # ===========================================================================
  # Celery Worker - Background Video Processing
  # ===========================================================================
  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: socialmediaai-celery-worker
    env_file:
      - backend/.env
    volumes:
      - ./backend:/app
      - backend-temp:/app/temp
    environment:
      - DEBUG=true
      - REDIS_URL=redis://redis:6379
    command: celery -A app.workers.celery_app worker --loglevel=info --concurrency=2
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - socialmediaai-network
    restart: unless-stopped

  # ===========================================================================
  # Celery Beat - Scheduled Tasks
  # ===========================================================================
  celery-beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: runtime
    container_name: socialmediaai-celery-beat
    env_file:
      - backend/.env
    volumes:
      - ./backend:/app
    environment:
      - DEBUG=true
      - REDIS_URL=redis://redis:6379
    command: celery -A app.workers.celery_app beat --loglevel=info
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - socialmediaai-network
    restart: unless-stopped

  # ===========================================================================
  # Redis - Cache & Celery Broker
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: socialmediaai-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    networks:
      - socialmediaai-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

# =============================================================================
# Networks
# =============================================================================
networks:
  socialmediaai-network:
    driver: bridge

# =============================================================================
# Volumes
# =============================================================================
volumes:
  redis-data:
    driver: local
  backend-temp:
    driver: local
